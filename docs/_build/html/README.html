

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Variant Calling with Swift-T &mdash; Swift_T_Variant_Calling 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Swift_T_Variant_Calling 1.0.0 documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Swift_T_Variant_Calling
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="Architecture.html">Intended pipeline architecture and function</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="UserGuide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="UnderTheHood.html">Under The Hood</a></li>
<li class="toctree-l1"><a class="reference internal" href="Troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeveloperGuide.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Citation.html">Citation and Licensing</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Swift_T_Variant_Calling</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Variant Calling with Swift-T</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/README.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="variant-calling-with-swift-t">
<h1>Variant Calling with Swift-T<a class="headerlink" href="#variant-calling-with-swift-t" title="Permalink to this headline">¶</a></h1>
<p>This repo is a complete Variant Calling pipeline written in Swift/T
language, for use in the analysis of Whole Genome and Whole Exome
Sequencing studies.</p>
<p>You may use this README file to get an idea of how the code is structred
and used, or visit an easier-to-read version of this documentaiton
available on <a class="reference external" href="http://swift-t-variant-calling.readthedocs.io/en/latest/">our companion
site</a></p>
<p>If you like to cite this code, please use this DOI: . See the Citation
guide (here)[] for more information.</p>
<p>Files in this repo are organized as follows:</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Folder</th>
<th class="head">Content</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">docs</span></code></td>
<td>The files for
the <cite>companion
site &lt;http://swi
ft-t-variant-cal
ling.readthedocs
.io/en/latest/&gt;</cite>
__</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">media</span></code></td>
<td>Various figures
containing
images used in
this README file</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">src</span></code></td>
<td>The source code
of the pipeline,
written in
Swift/T. See the
section <a class="reference external" href="#Under-The-Hood">Under
The
Hood</a>
for how it is
designed</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">test</span></code></td>
<td>Files for
testing the
pipeline on
different
platforms:
<cite>XSEDE &lt;https://
www.xsede.org/&gt;</cite>
__,
<a class="reference external" href="http://help.igb.illinois.edu/Biocluster2">Biocluster</a>,
<a class="reference external" href="https://bluewaters.ncsa.illinois.edu/">Blue
Waters</a>
_,
<a class="reference external" href="http://www.ncsa.illinois.edu/industry/iforge">iForge</a>,
and stand alone
server</td>
</tr>
</tbody>
</table>
<p><strong>Table of Contents</strong></p>
<ul class="simple">
<li><a class="reference external" href="#variant-calling-with-swift-t">Variant Calling with Swift-T</a><ul>
<li><a class="reference external" href="#intended-pipeline-architecture-and-function">Intended pipeline architecture and
function</a></li>
<li><a class="reference external" href="#installation">Installation</a><ul>
<li><a class="reference external" href="#dependencies">Dependencies</a></li>
<li><a class="reference external" href="#workflow-installation">Workflow Installation</a></li>
</ul>
</li>
<li><a class="reference external" href="#user-guide">User Guide</a><ul>
<li><a class="reference external" href="#runfile-options">Runfile Options</a></li>
<li><a class="reference external" href="#running-the-pipeline">Running the Pipeline</a><ul>
<li><a class="reference external" href="#requesting-resources-from-the-job-scheduler">Requesting Resources from the Job
Scheduler</a></li>
<li><a class="reference external" href="#executing-the-swift-t-application">Executing the Swift-T
Application</a><ul>
<li><a class="reference external" href="#pbs-torque-general">PBS Torque (general)</a></li>
<li><a class="reference external" href="#pbs-torque-alternative">PBS Torque (alternative)</a></li>
<li><a class="reference external" href="#cray-system-like-blue-waters-at-uiuc">Cray System (Like Blue Waters at
UIUC)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference external" href="#output-structure">Output Structure</a></li>
<li><a class="reference external" href="#logging-functionality">Logging functionality</a><ul>
<li><a class="reference external" href="#important-notes">Important Notes</a></li>
</ul>
</li>
<li><a class="reference external" href="#data-preparation">Data preparation</a></li>
<li><a class="reference external" href="#resource-requirements">Resource Requirements</a></li>
<li><a class="reference external" href="#pipeline-interruptions-and-continuations">Pipeline Interruptions and
Continuations</a><ul>
<li><a class="reference external" href="#background">Background</a></li>
<li><a class="reference external" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference external" href="#under-the-hood">Under The Hood</a></li>
<li><a class="reference external" href="#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
<div class="section" id="intended-pipeline-architecture-and-function">
<h2>Intended pipeline architecture and function<a class="headerlink" href="#intended-pipeline-architecture-and-function" title="Permalink to this headline">¶</a></h2>
<p>This pipeline implements the <a class="reference external" href="https://software.broadinstitute.org/gatk/best-practices/">GATK&#8217;s best
practices</a>
for germline variant calling in Whole Genome and Whole Exome Next
Generation Sequencing datasets, given a cohort of samples.</p>
<p>This pipeline was disigned for GATK 3.X, which include the following
stages:</p>
<ol class="arabic simple">
<li>Map to the reference genome</li>
<li>Mark duplicates</li>
<li>Perform indel realignment and/or base recalibration (BQSR)*</li>
<li>Call variants on each sample</li>
<li>Perform joint genotyping</li>
</ol>
<p>* The indel realignment step was recommended in GATK best practices &lt;
3.6).</p>
<p>Additionally, this workflow provides the option to split the aligned
reads by chromosome before calling variants, which often speeds up
performance when analyzing WGS data.</p>
<p><strong>Figure 1:</strong> Overview of Workflow Design</p>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dependencies">
<h3>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h3>
<p>| <strong>Step</strong> | <strong>Tool options</strong> | | &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8211;|
&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;|
| Alignment | <a class="reference external" href="https://github.com/lh3/bwa">Bwa mem</a> or
<a class="reference external" href="http://novocraft.com/">Novoalign</a> | | Sorting |
<a class="reference external" href="http://novocraft.com/">Novosort</a> | | Marking Duplicates |
<a class="reference external" href="https://github.com/GregoryFaust/samblaster">Samblaster</a>,
<a class="reference external" href="http://novocraft.com/">Novosort</a>, or
<a class="reference external" href="https://broadinstitute.github.io/picard/">Picard</a> | | Indel
Realignment |
<a class="reference external" href="https://software.broadinstitute.org/gatk/download/">GATK</a> | | Base
Recalibration |
<a class="reference external" href="https://software.broadinstitute.org/gatk/download/">GATK</a> | |
Variant Calling |
<a class="reference external" href="https://software.broadinstitute.org/gatk/download/">GATK</a> | |
Joint Genotyping |
<a class="reference external" href="https://software.broadinstitute.org/gatk/download/">GATK</a> | |
Miscellaneous | <a class="reference external" href="http://samtools.github.io/">Samtools</a> |</p>
</div>
<div class="section" id="workflow-installation">
<h3>Workflow Installation<a class="headerlink" href="#workflow-installation" title="Permalink to this headline">¶</a></h3>
<p>At minimum, a working installation of Swift/T is needed. Depending on
your set up, find these instructions .</p>
<p>Next, you need to clone this repository</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">&lt;</span><span class="n">azza</span><span class="p">:</span> <span class="n">add</span> <span class="n">content</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Finally, if you need to visualize your results, you will need R
installed with the following packages:</p>
</div>
</div>
<div class="section" id="user-guide">
<h2>User Guide<a class="headerlink" href="#user-guide" title="Permalink to this headline">¶</a></h2>
<p>The workflow is controlled by modifying the variables contained within a
runfile.</p>
<p>A <code class="docutils literal"><span class="pre">template.runfile</span></code> is packaged within this repo.</p>
<p>From this file, one specifies how the workflow is ran</p>
<div class="section" id="runfile-options">
<h3>Runfile Options<a class="headerlink" href="#runfile-options" title="Permalink to this headline">¶</a></h3>
<p><strong>``SAMPLEINFORMATION``</strong></p>
<p>The file that contains the paths to each sample&#8217;s reads, where each
sample is on its own line in the form:
<code class="docutils literal"><span class="pre">SampleName</span> <span class="pre">/path/to/read1.fq</span> <span class="pre">/path/to/read2.fq</span></code>. Alternatively, if
analyzing single-end reads, the format is simply:
<code class="docutils literal"><span class="pre">SampleName</span> <span class="pre">/path/to/read1.fq</span></code></p>
<p><em>It is necessary that no empty line is inserted at the end of this file</em></p>
<p><strong>``OUTPUTDIR``</strong> The path that will serve as the root of all of the
output files generated from the pipeline (See <code class="docutils literal"><span class="pre">Figure</span> <span class="pre">2</span></code>)</p>
<p><strong>``TMPDIR``</strong> The path to where temporary files will be stored (See
<code class="docutils literal"><span class="pre">Figure</span> <span class="pre">2</span></code>)</p>
<p><strong>``REALIGN``</strong> YES if one wants to realign before recalibration, NO if
not.</p>
<p><strong>``SPLIT``</strong> YES if one wants to split-by-chromosome before calling
variants, NO if not.</p>
<p><strong>``PROGRAMS_PER_NODE``</strong></p>
<p>Sometimes it is more efficent to double (or even triple) up runs of an
application on the same nodes using half of the available threads than
letting one run of the application use all of them. This is because many
applications only scale well up to a certain number of threads, and
often this is less than the total number of cores available on a node.</p>
<p>Under the hood, this variable simply controls how many threads each tool
gets. If <code class="docutils literal"><span class="pre">CORES_PER_NODE</span></code> is set to 20 but <code class="docutils literal"><span class="pre">PROGRAMS_PER_NODE</span></code> is
set to 2, each tool will use up to 10 threads.</p>
<p><strong>!!!!!!!!! IMPORTANT NOTE !!!!!!!!!</strong> It is up to the user at runtime
to be sure that the right number of processes are requested per node
when calling Swift-T itself (See the <code class="docutils literal"><span class="pre">Running</span> <span class="pre">the</span> <span class="pre">Pipeline</span></code> section),
as this is what actually controls how processes are distributed.</p>
<p><strong>``CORES_PER_NODE``</strong> Number of cores within nodes to be used in the
analysis. For multi-threaded tools, the number of threads =
<code class="docutils literal"><span class="pre">CORES_PER_NODE/PROGRAMS_PER_NODE</span></code></p>
<p><strong>``EXIT_ON_ERROR``</strong></p>
<p>If this is set to <code class="docutils literal"><span class="pre">YES</span></code>, the workflow will quit after a sample fails
quality control.</p>
<p>If set to <code class="docutils literal"><span class="pre">NO</span></code>, the workflow will let samples fail, and continue
processing all of those that did not. The workflow will only stop if
none of the samples remain after the failed ones are filtered out.</p>
<p>This option is provided because for large sample sets one may expect a
few of the input samples to fail quality control, and it may be
acceptable to keep going if a few fail. However, exercise caution and
monitor the <code class="docutils literal"><span class="pre">Failures.log</span></code> generated in the <code class="docutils literal"><span class="pre">DELIVERYFOLDER/docs</span></code>
folder to gauge how many of the samples are failing.</p>
<p><strong>``ALIGN_DEDUP_STAGE``; ``CHR_SPLIT_STAGE``; ``VC_STAGE``;
``COMBINE_VARIANT_STAGE``; ``JOINT_GENOTYPING_STAGE``</strong></p>
<p>These variables control whether each stage is ran or skipped (only
stages that were successfully run previously can be skipped, as the
&#8220;skipped&#8221; option simply looks for the output files that were generated
from a previous run.)</p>
<p>Each of these stage variables can be set to <code class="docutils literal"><span class="pre">Y</span></code> or <code class="docutils literal"><span class="pre">N</span></code>. In addition,
all but the last stage can be set to <code class="docutils literal"><span class="pre">End</span></code>, which will stop the
pipeline after that stage has been executed (think of the <code class="docutils literal"><span class="pre">End</span></code>
setting as shorthand for &#8220;End after this stage&#8221;)</p>
<p>See the <strong>Pipeline Interruptions and Continuations</strong> Section for more
details.</p>
<p><strong>PAIRED</strong> 0 if reads are single-ended only; 1 if they are paired-end
reads</p>
<p><strong>ALIGNERTOOL; MARKDUPLICATESTOOL</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="71%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Process</strong></th>
<th class="head"><strong>Setting</strong></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Alignment</td>
<td><code class="docutils literal"><span class="pre">BWAMEM</span></code> or <code class="docutils literal"><span class="pre">NOVOALIGN</span></code></td>
</tr>
<tr class="row-odd"><td>Mark Duplicates</td>
<td><code class="docutils literal"><span class="pre">SAMBLASTER</span></code>, <code class="docutils literal"><span class="pre">PICARD</span></code>, or <code class="docutils literal"><span class="pre">NOVOSORT</span></code></td>
</tr>
</tbody>
</table>
<p><strong>``BWAINDEX``; ``NOVOALIGNINDEX``</strong> Depending on the tool being used,
one of these variables specify the location of the index file</p>
<p><strong>``BWAMEMPARAMS``; ``NOVOALIGNPARAMS``</strong></p>
<p>This string is passed directly as arguments to the tool as (an)
argument(s)</p>
<p>Example, <code class="docutils literal"><span class="pre">BWAMEMPARAMS=-k</span> <span class="pre">32</span> <span class="pre">-I</span> <span class="pre">300,30</span></code></p>
<p>Note: There is no space between the &#8216;=&#8217; character and your parameters
Note: Do not set the thread count or paired/single-ended flags, as they
are taken care of by the workflow itself</p>
<p><strong>``CHRNAMES``</strong></p>
<p>List of chromosome/contig names separated by a &#8216;:&#8217;</p>
<p>Examples: * <code class="docutils literal"><span class="pre">chr1:chr2:chr3</span></code> * <code class="docutils literal"><span class="pre">1:2:3</span></code></p>
<p>Note: chromosome names must match those found in the files located in
the directory that <code class="docutils literal"><span class="pre">INDELDIR</span></code> points to, as well as those in the
reference fasta files</p>
<p><strong>``NOVOSORT_MEMLIMIT``</strong></p>
<p>Novosort is a tool that used a lot of RAM. If doubling up novosort runs
on the same node, this may need to be reduced to avoid an OutOfMemory
Error. Otherwise, just set it to most of the RAM on a node. <em>You need to
set this value regardless of you analysis scenario</em></p>
<p>This is set in bytes, so if you want to limit novosort to using 30 GB,
one would set it to <code class="docutils literal"><span class="pre">NOVOSORT_MEMLIMIT=30000000000</span></code></p>
<p><strong>``MAP_CUTOFF``</strong> The minimum percentage of reads that were
successfully mapped in a successful alignment</p>
<p><strong>``DUP_CUTOFF``</strong> The maximum percentage of reads that are marked as
duplicates in a successful sample</p>
<p><strong>``REFGENOME``</strong> Full path to the reference genome
(/path/to/example.fa)(assumes reference has .dict and .fai (index) files
created in the same directory)</p>
<p><strong>``DBSNP``</strong> Full path to the dbsnp vcf file (GATK assumes that this
vcf is also indexed)</p>
<p><strong>``INDELDIR``</strong></p>
<p>Directory that contains the standard indel variant files used in the
realignment/recalibration step</p>
<p>(Full path to directory)</p>
<p>Within the directory, the vcf files should be named with only the
chromosome name in front and nothing else.</p>
<p>For example, if the chromosome is <code class="docutils literal"><span class="pre">chr12</span></code> or <code class="docutils literal"><span class="pre">12</span></code>, name the vcf
files <code class="docutils literal"><span class="pre">chr12.vcf</span></code> or <code class="docutils literal"><span class="pre">12.vcf</span></code>, respectively.</p>
<p>If not splitting by chromosome, the workflow will look for all of the
vcf files in the directory.</p>
<p><strong>``JAVAEXE``; ``BWAEXE``; ``SAMBLASTEREXE``; ``SAMTOOLSEXE``;
``NOVOALIGNEXE``; ``NOVOSORTEXE``</strong></p>
<p>Full path of the appropriate executable file</p>
<p><strong>``PICARDJAR``; ``GATKJAR``</strong> Full path of the appropriate jar file</p>
<p><strong>``JAVA_MAX_HEAP_SIZE``</strong> Memory area to store all java objects. This
should be tuned in relevance to the speed and frequency at which garbage
collection should occur. With larger input size, larger heap is needed.</p>
</div>
<div class="section" id="running-the-pipeline">
<h3>Running the Pipeline<a class="headerlink" href="#running-the-pipeline" title="Permalink to this headline">¶</a></h3>
<div class="section" id="requesting-resources-from-the-job-scheduler">
<h4>Requesting Resources from the Job Scheduler<a class="headerlink" href="#requesting-resources-from-the-job-scheduler" title="Permalink to this headline">¶</a></h4>
<p>Swift-T works by opening up multiple &#8220;slots&#8221;, called processes, where
applications can run. There are two types of processes this workflow
allocates * SERVERS - Control the execution of Swift-T itself; all
Swift-T applications must have at least one of these * WORKERS - Run
the actual work of each application in the workflow; these will make up
the vast majority of processes</p>
<p>Controlling various aspects of the job submission is achieved by setting
environment variables to the desired values. For example, the user can
fine control the total number of processes needed by setting
<code class="docutils literal"><span class="pre">PROCS=&lt;Number</span> <span class="pre">of</span> <span class="pre">MPI</span> <span class="pre">processes&gt;</span></code>, and/or the number of workers via
<code class="docutils literal"><span class="pre">TURBINE_WORKERS</span></code> and the number of servers via <code class="docutils literal"><span class="pre">ADLB_SERVERS</span></code>.
Similarly, one can specify <code class="docutils literal"><span class="pre">QUEUE</span></code>, <code class="docutils literal"><span class="pre">WALLTIME</span></code> and <code class="docutils literal"><span class="pre">PROJECT</span></code>
specifications. More coverage of these is provided in <a class="reference external" href="http://swift-lang.github.io/swift-t/sites.html#variables">the Swift/T sites
guide</a>.</p>
<p>Other options allow control of logging options. Especially for users
unfamiliar with Swift/T, we recommend always setting the environment
variable <code class="docutils literal"><span class="pre">ADLB_DEBUG_RANKS=1</span></code> and checking the beginning of the
Swift/T log to be sure processes are being allocated as the user
expects.</p>
<p>Often when we use a cluster we set the <code class="docutils literal"><span class="pre">PPN</span></code> variable to the number of
cores on each node. Swift/T will allocate PPN processes on each node.
Normally, we set PPN to the number of cores for maximal concurrency,
although the PPN setting can be use to over- or under-subscribe
processes. For example, an application that is short on memory might set
a lower PPN, where an I/O intensive application might set a higher PPN.</p>
<p>For convenience, we recommend setting all such environment variables in
a file, and then adding it to the Swift/T command. This is shown in the
sections below for different schedulers (pbs, cray, slurm).</p>
</div>
<div class="section" id="executing-the-swift-t-application">
<h4>Executing the Swift-T Application<a class="headerlink" href="#executing-the-swift-t-application" title="Permalink to this headline">¶</a></h4>
<p>If using multiple nodes, one should set the <code class="docutils literal"><span class="pre">SWIFT_TMP</span></code> to another
location besides the default <code class="docutils literal"><span class="pre">/tmp</span></code>, that is shared by all of the
nodes</p>
<p>For example, <code class="docutils literal"><span class="pre">export</span> <span class="pre">SWIFT_TMP=/path/to/home/directory/temp</span></code></p>
<p>On Blue Waters, SWIFT_TMP should probably be in /scratch .</p>
<p><strong>The type of job scheduler dictates how one calls Swift-T</strong></p>
<div class="section" id="pbs-torque-general">
<h5>PBS Torque (general)<a class="headerlink" href="#pbs-torque-general" title="Permalink to this headline">¶</a></h5>
<p>Usually, one can use swift-t&#8217;s built-in job launcher for PBS Torque
schedulers (calling swift-t with <code class="docutils literal"><span class="pre">-m</span> <span class="pre">pbs</span></code>)</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ cat settings.sh       # For convenience, we save all environment variables in a file named settings.sh for example
export PPN=&lt;PROGRAMS_PER_NODE&gt;
export NODES=&lt;#samples/PROGRAMS_PER_NODE + (1 or more)&gt;
export PROCS=$(($PPN * $NODES))
export WALLTIME=&lt;HH:MM::SS&gt;
export PROJECT=&lt;Project ID&gt;
export QUEUE=&lt;queue&gt;
export SWIFT_TMP=/path/to/directory/temp

# (Optional variables to set)
export TURBINE_LOG=1
export ADLB_DEBUG_RANKS=1
export TURBINE_OUTPUT=/path/to/output_log_location

$ swift-t -m pbs -O3 -s settings.sh -o /path/to/where/compiled/should/be/saved/compiled.tic -I /path/to/Swift-T-Variant-Calling/src/ -r /path/to/Swift-T-Variant-Calling/src/bioapps /path/to/Swift-T-Variant-Calling/src/VariantCalling.swift -runfile=/path/to/your.runfile
</pre></div>
</div>
<p>This command will compile and run the pipeline all in one command, and
the flags used in this call do the following:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">-O3</span></code> Conduct full optimizations of the Swift-T code during
compilation (Even with full optimizations, compilation of the code
takes only around 3 seconds)</li>
<li><code class="docutils literal"><span class="pre">-m</span> <span class="pre">pbs</span></code> The job scheduler type, pbs torque in this case</li>
<li><code class="docutils literal"><span class="pre">-s</span> <span class="pre">settings.sh</span></code> The file with environment variables&#8217; settings for
the scheduler</li>
<li><code class="docutils literal"><span class="pre">-o</span></code> The path to the compiled swift-t file (has a .tic extension);
on the first run, this file will be created.</li>
<li><code class="docutils literal"><span class="pre">-I</span></code> This includes some source files that are imported during
compilation</li>
<li><code class="docutils literal"><span class="pre">-r</span></code> This includes some tcl package files needed during compilation</li>
<li><code class="docutils literal"><span class="pre">-n</span></code> The number of processes (ranks) Swift-T will open for this run
of the workflow <strong>(this overrides the PROCS specification above, so
I&#8217;m not sure we should use both &#8211; ask/advise)</strong></li>
<li><code class="docutils literal"><span class="pre">-runfile</span></code> The path to the runfile with all of the configuration
variables for the workflow</li>
</ul>
</div>
<div class="section" id="pbs-torque-alternative">
<h5>PBS Torque (alternative)<a class="headerlink" href="#pbs-torque-alternative" title="Permalink to this headline">¶</a></h5>
<p>If you need to import a module to use Swift/T (as is the case on iForge
at UIUC), one cannot simply use the swift-t launcher as outlined above,
since the module load command is not part of the qsub file that Swift-t
generates and submits.</p>
<p>This command must be included (along with any exported environment
variables and module load commands) in a job submission script and not
called directly on a head/login node.</p>
<p><code class="docutils literal"><span class="pre">swift-t</span> <span class="pre">-O3</span> <span class="pre">-o</span> <span class="pre">&lt;/path/to/compiled_output_file.tic&gt;</span> <span class="pre">-I</span> <span class="pre">/path/to/Swift-T-Variant-Calling/src</span> <span class="pre">-r</span> <span class="pre">/path/to/Swift-T-Variant-Calling/src/bioapps</span> <span class="pre">-n</span> <span class="pre">&lt;</span> <span class="pre">Node#</span> <span class="pre">*</span> <span class="pre">PROGRAMS_PER_NODE</span> <span class="pre">+</span> <span class="pre">1</span> <span class="pre">or</span> <span class="pre">more</span> <span class="pre">&gt;</span> <span class="pre">/path/to/Swift-T-Variant-Calling/src/VariantCalling.swift</span> <span class="pre">-runfile=/path/to/example.runfile</span></code></p>
<p>It is important to note that (at least for PBS Torque schedulers) when
submitting a qsub script, the <code class="docutils literal"><span class="pre">ppn</span></code> option should be set, not to the
number of cores on each compute node, but to the number of WORKERS
Swift-T needs to open up on that node.</p>
<p><strong>Example</strong></p>
<p>If one is wanting to run a 4 sample job with <code class="docutils literal"><span class="pre">PROGRAMS_PER_NODE</span></code> set
to 2 in the runfile (meaning that two BWA runs can be executing
simultaneously on a given node, for example), one would set the PBS flag
to <code class="docutils literal"><span class="pre">-l</span> <span class="pre">nodes=2:ppn=2</span></code> and the <code class="docutils literal"><span class="pre">-n</span></code> flag when calling the workflow to
5 ( nodes*ppn + 1 )</p>
</div>
<div class="section" id="cray-system-like-blue-waters-at-uiuc">
<h5>Cray System (Like Blue Waters at UIUC)<a class="headerlink" href="#cray-system-like-blue-waters-at-uiuc" title="Permalink to this headline">¶</a></h5>
<p>Configuring the workflow to work in this environment requires a little
more effort.</p>
<p>Create and run the automated qsub builder</p>
<p>To get the right number of processes on each node to make the
<code class="docutils literal"><span class="pre">PROGRAMS_PER_NODE</span></code> work correctly, one must set
<code class="docutils literal"><span class="pre">PPN=</span> <span class="pre">PROGRAMS_PER_NODE</span></code> and <code class="docutils literal"><span class="pre">NODES</span></code> to
<code class="docutils literal"><span class="pre">#samples/PROGRAMS_PER_NODE</span> <span class="pre">+</span> <span class="pre">(1</span> <span class="pre">or</span> <span class="pre">more)</span></code>, because at least one
process must be a Swift-T SERVER. If one wanted to try running 4 samples
on 2 nodes but with <code class="docutils literal"><span class="pre">PPN=3</span></code> to make room for the processes that need
to be SERVER types, one of the nodes may end up with 3 of your WORKER
processes running simultaneously, which may lead to memory problems when
Novosort is called.</p>
<p>(The exception to this would be when using a single node. In that case,
just set <code class="docutils literal"><span class="pre">PPN=#PROGRAMS_PER_NODE</span> <span class="pre">+</span> <span class="pre">1</span></code>)</p>
<p>So, with that understanding, call swift-t in the following way:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ cat settings.sh
export PPN=&lt;PROGRAMS_PER_NODE&gt;
export NODES=&lt;#samples/PROGRAMS_PER_NODE + (1 or more)&gt;
export PROCS=$(($PPN * $NODES))
export WALLTIME=&lt;HH:MM:SS&gt;
export PROJECT=&lt;Project ID&gt;
export QUEUE=&lt;Queue&gt;
export SWIFT_TMP=/path/to/directory/temp

# CRAY specific settings:
export CRAY_PPN=true

# (Optional variables to set)
export TURBINE_LOG=1    # This produces verbose logging info; great for debugging
export ADLB_DEBUG_RANKS=1   # Displays layout of ranks and nodes
export TURBINE_OUTPUT=/path/to/log/directory    # This specifies where the log info will be stored; defaults to one&#39;s home directory

$ swift-t -m cray -O3 -n $PROCS -o /path/to/where/compiled/should/be/saved/compiled.tic \
-I /path/to/Swift-T-Variant-Calling/src/ -r /path/to/Swift-T-Variant-Calling/src/bioapps \
/path/to/Swift-T-Variant-Calling/src/VariantCalling.swift -runfile=/path/to/your.runfile
</pre></div>
</div>
<p>Kill, fix, and rerun the generated qsub file</p>
<p>Swift-T will create and run the qsub command for you, however, this one
will fail if running on two or more nodes, so immediately kill it. Now
we must edit the qsub script swift produced</p>
<p>To fix this, we need to add a few variables to the submission file that
was just created.</p>
<p>The file will be located in the <code class="docutils literal"><span class="pre">$SWIFT_TMP</span></code> directory and will be
called <code class="docutils literal"><span class="pre">turbine-cray.sh</span></code></p>
<p>Add the following items to the file:</p>
<p><code class="docutils literal"><span class="pre">#PBS</span> <span class="pre">-V</span></code></p>
<p># Note: Make sure this directory is created before running the workflow,
and make sure it is not just &#8216;/tmp&#8217;</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">SWIFT_TMP</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">tmp_dir</span>
<span class="n">export</span> <span class="n">TMPDIR</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">tmp_dir</span>
<span class="n">export</span> <span class="n">TMP</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">tmp_dir</span>
</pre></div>
</div>
<p>Now, if you submit the turbine-cray.sh script with qsub, it should work</p>
</div>
<div class="section" id="slurm-based-systems-like-biocluster2-at-uiuc-and-stampede1-stampede2-on-xsede">
<h5>SLURM based Systems (Like Biocluster2 at UIUC, and Stampede1/Stampede2 on XSEDE)<a class="headerlink" href="#slurm-based-systems-like-biocluster2-at-uiuc-and-stampede1-stampede2-on-xsede" title="Permalink to this headline">¶</a></h5>
<p>As in the case with the pbs-based clusters, it is sufficient to only
specify the scheduler using <code class="docutils literal"><span class="pre">-m</span> <span class="pre">slurm</span></code>, and then proceed as above.
Additionaly, the same <code class="docutils literal"><span class="pre">settings.sh</span></code> file can be used, except that the
user can also instruct the scheduler to send email notifications as
well. The example below clarifies these:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ cat settings.sh
export PPN=&lt;PROGRAMS_PER_NODE&gt;
export NODES=&lt;#samples/PROGRAMS_PER_NODE + (1 or more)&gt;
export PROCS=$(($PPN * $NODES))
export WALLTIME=&lt;HH:MM:SS&gt;
export PROJECT=&lt;Project ID&gt;
export QUEUE=&lt;Queue&gt;
export SWIFT_TMP=/path/to/directory/temp

# SLURM specific settings
export  MAIL_ENABLED=1
export  MAIL_ADDRESS=&lt;the desired email address for sending notifications- on job start, fail and finish &gt;
export TURBINE_SBATCH_ARGS=&lt;Other optional arguments passed to sbatch, like --exclusive and --constraint=.. etc&gt;

# (Optional variables to set)
export TURBINE_LOG=1    # This produces verbose logging info; great for debugging
export ADLB_DEBUG_RANKS=1   # Displays layout of ranks and nodes
export TURBINE_OUTPUT=/path/to/log/directory    # This specifies where the log info will be stored; defaults to one&#39;s home directory

$ swift-t -m slurm -O3 -n $PROCS -o /path/to/where/compiled/should/be/saved/compiled.tic \
-I /path/to/Swift-T-Variant-Calling/src/ -r /path/to/Swift-T-Variant-Calling/src/bioapps \
/path/to/Swift-T-Variant-Calling/src/VariantCalling.swift -runfile=/path/to/your.runfile
</pre></div>
</div>
</div>
<div class="section" id="systems-without-a-resource-manager">
<h5>Systems without a resource manager:<a class="headerlink" href="#systems-without-a-resource-manager" title="Permalink to this headline">¶</a></h5>
<p>For these system, specifying the <code class="docutils literal"><span class="pre">settings.sh</span></code> file as above doesn&#8217;t
really populate the options to turbine when using
<code class="docutils literal"><span class="pre">Swift/T</span> <span class="pre">version</span> <span class="pre">1.2</span></code>. The workaround in such cases would be to export
the settings directly to the environment, and <code class="docutils literal"><span class="pre">nohup</span></code> or <code class="docutils literal"><span class="pre">screen</span></code>
the script launching the swift/t pipeline. Below is a good example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ cat runpipeline.sh
#!/bin/bash
export PROCS=$( PROGRAMS_PER_NODE * (#samples/PROGRAMS_PER_NODE + (1 or more)))
export SWIFT_TMP=/path/to/directory/temp

# (Optional variables to set)
export TURBINE_LOG=1    # This produces verbose logging info; great for debugging
export ADLB_DEBUG_RANKS=1   # Displays layout of ranks and nodes
export TURBINE_OUTPUT=/path/to/log/directory    # This specifies where the log info will be stored; defaults to one&#39;s home directory

$ swift-t -O3 -l -u -o /path/to/where/compiled/should/be/saved/compiled.tic \
-I /path/to/Swift-T-Variant-Calling/src/ -r /path/to/Swift-T-Variant-Calling/src/bioapps \
/path/to/Swift-T-Variant-Calling/src/VariantCalling.swift -runfile=/path/to/your.runfile

echo -e &quot;Swift-T pipeline run on $HOSTNAME has concluded successfully!&quot; | mail -s &quot;swift_t_pipeline&quot; &quot;your_email&quot;

$
$ nohup ./runpipeline.sh &amp;&gt; log.runpipeline.swift.t.nohup &amp;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="output-structure">
<h3>Output Structure<a class="headerlink" href="#output-structure" title="Permalink to this headline">¶</a></h3>
<p><strong>Figure 2:</strong> Output directories and files generated from a typical run
of the pipeline</p>
</div>
<div class="section" id="logging-functionality">
<h3>Logging functionality<a class="headerlink" href="#logging-functionality" title="Permalink to this headline">¶</a></h3>
<div class="section" id="swift-t-logging-options">
<h4>Swift/T logging options<a class="headerlink" href="#swift-t-logging-options" title="Permalink to this headline">¶</a></h4>
<p>While the outputs generated by all the tools of the workflow itself will
be logged in the log folders within the <code class="docutils literal"><span class="pre">OUTDIR</span></code> structure, Swift-T
generates a log itself that may help debug if problems occur.</p>
<p>Setting the environment variable <code class="docutils literal"><span class="pre">TURBINE_LOG=1</span></code> will make the log
quite verbose</p>
<p>Setting <code class="docutils literal"><span class="pre">ADLB_DEBUG_RANKS=1</span></code> will allow one to be sure the processes
are being allocated to the nodes in the way one expects</p>
</div>
<div class="section" id="workflow-logging-options">
<h4>Workflow logging options<a class="headerlink" href="#workflow-logging-options" title="Permalink to this headline">¶</a></h4>
<p>The provided scripts allow you to check out the trace of a successful
run of the pipeline. To invoke it, and for the time being, you need R
installed in your environment along with the <code class="docutils literal"><span class="pre">shiny</span></code> package.</p>
<p>To do so, proceed as follows:</p>
<ol class="arabic simple">
<li>Go to the <a class="reference external" href="http://ftp.heanet.ie/mirrors/cran.r-project.org/">R-project
webpage</a>, and
follow the instructions based on your system</li>
<li>Once the step above is completed and R is installed, open a terminal
window, type <code class="docutils literal"><span class="pre">R</span></code>, then proceed as follows:</li>
</ol>
<div class="highlight-default"><div class="highlight"><pre><span></span>if (!require(shiny)) {
    install.packages(&#39;shiny&#39;)
    library(shiny)
}
runGitHub(repo = &quot;ncsa/Swift-T-Variant-Calling&quot;, ref = &quot;master&quot;,
          subdir = &quot;src/plotting_app&quot; )
</pre></div>
</div>
<p>The first time you run these commands in your system it will also
install some libraries for you in case you don&#8217;t have them already,
namely: <code class="docutils literal"><span class="pre">lubridate,</span> <span class="pre">tidyverse</span> <span class="pre">and</span> <span class="pre">forcats</span></code>.</p>
<p>Once all is done, a webpage should open up for you to actually take a
look at your trace files. For a taste of how things look, you may take a
look at the sample <code class="docutils literal"><span class="pre">Timing.log</span></code> file provided <a class="reference external" href="https://github.com/jacobrh91/Swift-T-Variant-Calling/master/src/plotting_app">in the
repo</a></p>
<p>To take a look at your own analysis trace, you need to have a copy of
this branch first, Run it on you samples, and then find your own
<code class="docutils literal"><span class="pre">Timing.log</span></code> file within <code class="docutils literal"><span class="pre">&lt;OUTPUTDIR&gt;/delivery/docs</span></code>, where
<code class="docutils literal"><span class="pre">OUTPUTDIR</span></code> is specified as per the <a class="reference external" href="#user-guide">runfile</a>. Simply
upload this file, and start using the app.</p>
</div>
<div class="section" id="important-notes">
<h4>Important Notes<a class="headerlink" href="#important-notes" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>To investigate a partial pipeline run, you may <code class="docutils literal"><span class="pre">cat</span></code> the contents
of all the small files in your <code class="docutils literal"><span class="pre">TMPDIR</span></code> (See
<a class="reference external" href="#user-guide">runfile</a> options). In the example below, the
contents of thid directory are catted to the
<code class="docutils literal"><span class="pre">partial_run_timing.log</span></code>, which is then uploaded to the logging
webpage.</li>
</ul>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ cd &lt;TMPDIR&gt; #TMPDIR is what has been specified in the runfile
$ find . -name &#39;*.txt&#39; -exec cat {} \; &gt; partial_run_timing.log
</pre></div>
</div>
<ul class="simple">
<li>The overall summary tab of the logging webpage is handy in
summarizing which samples, and which chromosomes have run
successfully. It is easier to look at it when in doubt.</li>
<li>Running this pipeline in its current form is expected to be more
expensive than normal, due to the manual logging involved. The
alternative is to use the native <code class="docutils literal"><span class="pre">MPE</span></code> library (or equivalent),
which requires re-compiling the Swift/T source. This approach is
<strong>currently limited at the moment</strong>, but some discussions with the
Swift/T team on this is found
<a class="reference external" href="https://github.com/swift-lang/swift-t/issues/118">here</a></li>
</ul>
</div>
</div>
<div class="section" id="data-preparation">
<h3>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h3>
<p>For this pipeline to work, a number of standard files for calling
variants are needed (besides the raw reads files which can be
fastq/fq/fastq.gz/fq.gz), namely these are the reference sequence and
database of known variants (Please see this
<a class="reference external" href="https://software.broadinstitute.org/gatk/guide/article?id=1247">link</a>).</p>
<p>For working with human data, one can download most of the needed files
from <a class="reference external" href="http://gatkforums.broadinstitute.org/gatk/discussion/1213/whats-in-the-resource-bundle-and-how-can-i-get-it">the GATK’s resource
bundle</a>.
Missing from the bundle are the index files for the aligner, which are
specific to the tool that would be used for alignment (i.e., bwa or
novoalign in this pipeline)</p>
<p>Generally, for the preparation of the reference sequence, the following
link is a good start <a class="reference external" href="http://gatkforums.broadinstitute.org/wdl/discussion/2798/howto-prepare-a-reference-for-use-with-bwa-and-gatk">the GATK’s
guidelines</a>.</p>
<p>If splitting by chromosome for the
realignment/recalibration/variant-calling stages, the pipeline needs a
separate vcf file of known variants for each chromosome/contig, and each
should be named as: <code class="docutils literal"><span class="pre">*${chr_name}.vcf</span></code> . Further, all these files need
to be in the <code class="docutils literal"><span class="pre">INDELDIR</span></code> which should be within the <code class="docutils literal"><span class="pre">REFGENOMEDIR</span></code>
directory as per the <a class="reference external" href="#user-guide">runfile</a>.</p>
</div>
<div class="section" id="resource-requirements">
<h3>Resource Requirements<a class="headerlink" href="#resource-requirements" title="Permalink to this headline">¶</a></h3>
<p>The table below describes the number of does each stage needs to achieve
the maximum level of parallelism. One can request fewer resources if
necessary, but at the cost of having some portions running in series.</p>
<table border="1" class="docutils">
<colgroup>
<col width="71%" />
<col width="29%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Analysis Stage</strong></th>
<th class="head"><strong>Resource
Requirements</strong></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Alignment</td>
<td>Nodes = Samples /
(PROGRAMS_PER_NODE
*)</td>
</tr>
<tr class="row-odd"><td>Deduplication and sorting</td>
<td>Nodes = Samples /
(PROGRAMS_PER_NODE
*)</td>
</tr>
<tr class="row-even"><td>Split by Chromosome/Contig</td>
<td>Nodes = (Samples *
Chromosomes)/
PROGRAMS_PER_NODE*</td>
</tr>
<tr class="row-odd"><td>Realignment, Recalibration, and Variant Calling
(w/o splitting by chr)</td>
<td>Nodes = Samples /
(PROGRAMS_PER_NODE
*)</td>
</tr>
<tr class="row-even"><td>Realignment, Recalibration, and Variant Calling (w/
splitting by chr)</td>
<td>Nodes = (Samples *
Chromosomes)/
PROGRAMS_PER_NODE*</td>
</tr>
<tr class="row-odd"><td>Combine Sample Variants</td>
<td>Nodes = Samples /
(PROGRAMS_PER_NODE
*)</td>
</tr>
<tr class="row-even"><td>Joint Genotyping</td>
<td>Nodes = 1**</td>
</tr>
</tbody>
</table>
<p>* PROGRAMS_PER_NODE is a variable set in the runfile. Running 10
processes using 20 threads in series may actually be slower than running
the 10 processes in pairs utilizing 10 threads each</p>
<p>** The call to GATK&#8217;s GenotypeGVCFs must be done on a single node. It
is best to separate out this stage into its own job submission, so as to
not waste unused resources.</p>
</div>
<div class="section" id="pipeline-interruptions-and-continuations">
<h3>Pipeline Interruptions and Continuations<a class="headerlink" href="#pipeline-interruptions-and-continuations" title="Permalink to this headline">¶</a></h3>
<div class="section" id="background">
<h4>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h4>
<p>Because of the varying resource requirements at various stages of the
pipeline, the workflow allows one to stop the pipeline at many stages
and jump back in without having to recompute.</p>
<p>This feature is controlled by the STAGE variables of the runfile. At
each stage, the variable can be set to &#8220;Y&#8221; if it should be computed, and
&#8220;N&#8221; if that stage was completed on a previous execution of the workflow.
If &#8220;N&#8221; is selected, the program will simply gather the output that
should have been generated from a previous run and pass it to the next
stage.</p>
<p>In addition, one can set each stage but the final one to &#8220;End&#8221;, which
will stop the pipeline after that stage has been executed. Think of
&#8220;End&#8221; as a shorthand for &#8220;End after this stage&#8221;.</p>
</div>
<div class="section" id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h4>
<p>If splitting by chromosome, it may make sense to request different
resources at different times.</p>
<p>One may want to execute only the first two stages of the workflow with #
Nodes = # Samples. For this step, one would use these settings:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ALIGN_STAGE</span><span class="o">=</span><span class="n">Y</span>
<span class="n">DEDUP_SORT_STAGE</span><span class="o">=</span><span class="n">Y</span>
<span class="n">CHR_SPLIT_STAGE</span><span class="o">=</span><span class="n">End</span>         <span class="c1"># This will be the last stage that is executed</span>
<span class="n">VC_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">COMBINE_VARIANT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">JOINT_GENOTYPING_STAGE</span><span class="o">=</span><span class="n">N</span>
</pre></div>
</div>
<p>Then for the variant calling step, where the optimal resource
requirements may be something like # Nodes = (# Samples * #
Chromosomes), one could alter the job submission script to request more
resources, then use these settings:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ALIGN_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">DEDUP_SORT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">CHR_SPLIT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">VC_STAGE</span><span class="o">=</span><span class="n">End</span>                <span class="c1"># Only this stage will be executed</span>
<span class="n">COMBINE_VARIANT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">JOINT_GENOTYPING_STAGE</span><span class="o">=</span><span class="n">N</span>
</pre></div>
</div>
<p>Finally, for the last two stages, where it makes sense to set # Nodes =
# Samples again, one could alter the submission script again and use
these settings:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ALIGN_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">DEDUP_SORT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">CHR_SPLIT_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">VC_STAGE</span><span class="o">=</span><span class="n">N</span>
<span class="n">COMBINE_VARIANT_STAGE</span><span class="o">=</span><span class="n">Y</span>
<span class="n">JOINT_GENOTYPING_STAGE</span><span class="o">=</span><span class="n">Y</span>
</pre></div>
</div>
<p>This feature was designed to allow a more efficient use of computational
resources.</p>
</div>
</div>
</div>
<div class="section" id="under-the-hood">
<h2>Under The Hood<a class="headerlink" href="#under-the-hood" title="Permalink to this headline">¶</a></h2>
<p><strong>Figure 3:</strong> Program Structure</p>
<p>Each Run function has two paths it can use to produce its output: 1. One
path actually performs the computations of this stage of the pipeline 2.
The other skips the computations and just gathers the output of a prior
execution of this stage. This is useful when one wants to jump into
different sections of the pipeline, and also allows Swift/T&#8217;s dependency
driven execution to correctly string the stages together into one
workflow.</p>
</div>
<div class="section" id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<p><strong>General Troubleshooting Tips</strong></p>
<p>Regardless of the platform, one can use the following environmental
variables to better debug the workflow:</p>
<p><code class="docutils literal"><span class="pre">ADLB_DEBUG_RANKS=1</span></code> One can see if the processes are spread across
the nodes correctly</p>
<p><code class="docutils literal"><span class="pre">TURBINE_LOG=1</span></code> Makes the Swift-T log output very verbose
<code class="docutils literal"><span class="pre">TURBINE_LOG_FILE=&lt;filePath&gt;</span></code> Changes the Swift-T log output from
StdOut to the file of choice</p>
<p>More debug info can be found
<a class="reference external" href="http://swift-lang.github.io/swift-t/guide.html">here</a></p>
<ul class="simple">
<li>The pipeline seems to be running, but then prematurely stops at one
of the tools?</li>
<li>Solution: make sure that all tools are specified in your runfile up
to the executable itself (or the jar file if applicable)</li>
<li>The realignment/recalibration stage produces a lot of errors or
strange results?</li>
<li>Solution: make sure you are preparing your reference and extra files
(dbsnp, 1000G,...etc) according to the guidelines in the <a class="reference external" href="#data-preparation">Data
Preparation</a> section</li>
<li>Things that should be running in parallel appear to be running
sequencially</li>
<li>Solution: make sure you are setting the <code class="docutils literal"><span class="pre">-n</span></code> flag to a value at
least one more than <code class="docutils literal"><span class="pre">PROGRAMS_PER_NODE</span></code> * <code class="docutils literal"><span class="pre">NODES</span></code>, as this
allocates processes for Swift/T itself to run on</li>
<li>The job is killed as soon as BWA is called?</li>
<li>Solution: make sure there is no space in front of <code class="docutils literal"><span class="pre">BWAMEMPARAMS</span></code><ul>
<li>DO-THIS: <code class="docutils literal"><span class="pre">BWAMEMPARAMS=-k</span> <span class="pre">32</span> <span class="pre">-I</span> <span class="pre">300,30</span></code></li>
<li>NOT-THIS: <code class="docutils literal"><span class="pre">BWAMEMPARAMS=</span> <span class="pre">-k</span> <span class="pre">32</span> <span class="pre">-I</span> <span class="pre">300,30</span></code></li>
</ul>
</li>
<li>I&#8217;m not sure how to run on a cluster that uses torque as a resource
manager?</li>
<li>Clusters are typically configured to kill head node jobs that run
longer than a few minutes, to prevent users from hogging the head
node. Therefore, you may qsub the initial job, the swift-t command
with its set variables, and it will qsub everybody else from its
compute node.</li>
<li>I&#8217;m having difficulty running the plotting app. I get an error
regarding plotly</li>
<li>The logging app depends on many R packages, including <code class="docutils literal"><span class="pre">plotly</span></code> and
<code class="docutils literal"><span class="pre">tidyverse</span></code>. Some of these packages however require some OS
specific packages. Fore deb systems (Debian, Ubuntu, ..etc), you may
need to install <code class="docutils literal"><span class="pre">libssl-dev</span></code> and <code class="docutils literal"><span class="pre">libcurl4-openssl-dev</span></code> with your
favourite package manager for <code class="docutils literal"><span class="pre">plotly</span></code> to work. Also, you may need
to install <code class="docutils literal"><span class="pre">libxml2-dev</span></code> for the <code class="docutils literal"><span class="pre">tidyverse</span></code> package to work</li>
</ul>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Azza Ahmed, Jacob R. Heldenbrand, Yan Asmann, Katherine Kendig, Matthew C. Kendzior, Tiffany Li, Yingxue Ren, Elliott Rodriguez, Matthew R. Weber, Jennie Zermeno, Faisal M. Fadlelmola, Daniel Katz, Liudmila S. Mainzer.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>